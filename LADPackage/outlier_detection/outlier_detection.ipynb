{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LADPackage Outlier Detection\n",
    "\n",
    "**Auto-Generated Script Converted from mFUSE**\n",
    "\n",
    "This notebook demonstrates a complete outlier detection workflow using structural health monitoring data from a 3-story structure. The workflow follows the LADPackage methodology and includes:\n",
    "\n",
    "1. **Data Import**: Loading 3-story structure dataset\n",
    "2. **Feature Extraction**: AR model parameter estimation\n",
    "3. **Feature Visualization**: Plotting feature vectors\n",
    "4. **Model Training**: Mahalanobis distance learning and scoring\n",
    "5. **Results Analysis**: Score visualization and distribution analysis\n",
    "6. **Performance Evaluation**: ROC curve analysis\n",
    "\n",
    "This example was originally created in mFUSE on 3/19/2016 and demonstrates the integration of multiple SHM analysis techniques in a single workflow.\n",
    "\n",
    "## Background\n",
    "\n",
    "Outlier detection in structural health monitoring aims to identify abnormal structural behavior that may indicate damage. This workflow uses:\n",
    "\n",
    "- **Autoregressive (AR) modeling** to extract time series features\n",
    "- **Mahalanobis distance** for statistical outlier detection\n",
    "- **ROC analysis** for performance quantification\n",
    "\n",
    "The methodology is particularly effective for detecting changes in structural dynamics caused by damage or environmental variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import numpy as np\nimport matplotlib.pyplot as plt\nimport sys\nfrom pathlib import Path\n\n# Add project root to path for imports\nnotebook_dir = Path().resolve()\nproject_root = notebook_dir.parent.parent\nsys.path.insert(0, str(project_root))\n\n# Import SHMTools modules\nfrom shmtools.features import ar_model_shm\nfrom shmtools.classification import roc_shm\nfrom shmtools.plotting import (\n    plot_features_shm,\n    plot_scores_shm, \n    plot_score_distributions_shm,\n    plot_roc_shm\n)\n\n# Import LADPackage-specific functions\nfrom LADPackage.utils import import_3story_structure_sub_floors, learn_score_mahalanobis\n\nprint(f\"Project root: {project_root}\")\nprint(\"LADPackage outlier detection workflow initialized\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import 3 Story Structure Dataset\n",
    "\n",
    "Import 3 story structure data using the LADPackage-compatible import function. This dataset contains:\n",
    "\n",
    "- **170 test instances**: 90 undamaged + 80 damaged conditions\n",
    "- **5 channels**: Force input + 4 acceleration measurements\n",
    "- **8192 time points**: per measurement at 2000 Hz sampling rate\n",
    "\n",
    "The data represents base excitation tests on a 3-story building structure with various damage scenarios including gap formation and mass changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Import 3 story structure data (empty list uses default: all channels)\ndataset, damage_states, state_list = import_3story_structure_sub_floors([])\n\nprint(f\"Dataset shape: {dataset.shape}\")\nprint(f\"Damage states shape: {damage_states.shape}\")\nprint(f\"State list shape: {state_list.shape}\")\nprint(f\"Unique damage states: {np.unique(damage_states)}\")\nprint(f\"Number of undamaged instances: {np.sum(damage_states == 0)}\")\nprint(f\"Number of damaged instances: {np.sum(damage_states == 1)}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: AR Model\n",
    "\n",
    "**AutoRegressive model (AR)** parameter estimation to extract features from the time series data.\n",
    "\n",
    "The AR model represents each time series as a linear combination of its past values:\n",
    "$$x(t) = \\sum_{i=1}^{p} a_i x(t-i) + e(t)$$\n",
    "\n",
    "Where:\n",
    "- $p = 10$ is the AR model order\n",
    "- $a_i$ are the AR parameters (our features)\n",
    "- $e(t)$ is the prediction error\n",
    "\n",
    "The AR parameters capture the structural dynamics and are sensitive to changes caused by damage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AR model order\n",
    "ar_order = 10\n",
    "\n",
    "# Extract AR model parameters as features\n",
    "ar_parameters_fv, rms_residuals_fv, ar_parameters, ar_residuals, ar_prediction = ar_model_shm(\n",
    "    dataset, ar_order\n",
    ")\n",
    "\n",
    "print(f\"AR parameters feature vectors shape: {ar_parameters_fv.shape}\")\n",
    "print(f\"RMS residuals feature vectors shape: {rms_residuals_fv.shape}\")\n",
    "print(f\"AR parameters shape: {ar_parameters.shape}\")\n",
    "print(f\"AR residuals shape: {ar_residuals.shape}\")\n",
    "print(f\"AR prediction shape: {ar_prediction.shape}\")\n",
    "\n",
    "# Display feature statistics\n",
    "print(f\"\\nFeature vector statistics:\")\n",
    "print(f\"Mean AR parameter magnitude: {np.mean(np.abs(ar_parameters_fv)):.4f}\")\n",
    "print(f\"Mean RMS residual: {np.mean(rms_residuals_fv):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Plot Features\n",
    "\n",
    "**Plot feature vectors as a subplot for each feature**\n",
    "\n",
    "Visualize the first 4 AR parameters across all test instances to observe how they vary between undamaged and damaged conditions. This helps identify which features are most sensitive to damage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Feature indices to plot (first 4 AR parameters)\nfeature_indices = np.array([0, 1, 2, 3])  # Python 0-based indexing\n\n# Plot features\naxes_handle = plot_features_shm(\n    ar_parameters_fv,\n    instance_indices=None,  # Plot all instances\n    feature_indices=feature_indices,\n    subplot_titles=None,  # Use default titles\n    subplot_ylabels=None,  # Use default labels\n    axes_handle=None\n)\n\nplt.suptitle('AR Model Parameters (Features 1-4)', fontsize=14, fontweight='bold')\nplt.tight_layout()\nplt.show()\n\nprint(f\"Plotted {len(feature_indices)} AR parameter features\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Learn Score Mahalanobis\n",
    "\n",
    "**Split data, train, and score using Mahalanobis distance**\n",
    "\n",
    "The Mahalanobis distance measures how far each instance is from the training data distribution, accounting for correlations between features:\n",
    "\n",
    "$$D_M(x) = \\sqrt{(x - \\mu)^T \\Sigma^{-1} (x - \\mu)}$$\n",
    "\n",
    "Where:\n",
    "- $\\mu$ is the mean of training features  \n",
    "- $\\Sigma$ is the covariance matrix of training features\n",
    "- $x$ is a test feature vector\n",
    "\n",
    "We use every other instance from the first 91 (indices 1:2:91 in MATLAB, 0:2:90 in Python) for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training indices: every other instance from first 91 (MATLAB 1:2:91)\n",
    "# Convert to Python 0-based indexing: 0:2:90\n",
    "training_indices = list(range(0, 91, 2))\n",
    "\n",
    "print(f\"Training indices (first 10): {training_indices[:10]}\")\n",
    "print(f\"Total training instances: {len(training_indices)}\")\n",
    "\n",
    "# Learn and score using Mahalanobis distance\n",
    "scores = learn_score_mahalanobis(ar_parameters_fv, training_indices)\n",
    "\n",
    "print(f\"\\nScores shape: {scores.shape}\")\n",
    "print(f\"Score statistics:\")\n",
    "print(f\"  Mean: {np.mean(scores):.4f}\")\n",
    "print(f\"  Std:  {np.std(scores):.4f}\")\n",
    "print(f\"  Min:  {np.min(scores):.4f}\")\n",
    "print(f\"  Max:  {np.max(scores):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Plot Scores\n",
    "\n",
    "**Plot bar graph showing detection results**\n",
    "\n",
    "Visualize the Mahalanobis distance scores as a bar graph. Higher scores typically indicate greater deviation from normal (training) conditions, suggesting potential damage.\n",
    "\n",
    "Parameters:\n",
    "- `flip_signs=True`: Makes higher scores more anomalous (if needed)\n",
    "- `use_log_scores=False`: Use linear scale for scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Plot scores as bar graph\nflip_signs = True\nuse_log_scores = False\n\n# Simple matplotlib bar plot\nplt.figure(figsize=(12, 6))\nx_indices = np.arange(len(scores))\nscores_to_plot = -scores.flatten() if flip_signs else scores.flatten()\n\n# Color based on damage states\ncolors = ['blue' if state == 0 else 'red' for state in damage_states.flatten()]\nplt.bar(x_indices, scores_to_plot, color=colors, alpha=0.7)\n\nplt.title('Mahalanobis Distance Scores', fontsize=14, fontweight='bold')\nplt.xlabel('Test Instance')\nplt.ylabel('Mahalanobis Distance')\nplt.grid(True, alpha=0.3)\n\n# Add legend\nfrom matplotlib.patches import Patch\nlegend_elements = [Patch(facecolor='blue', label='Undamaged'),\n                  Patch(facecolor='red', label='Damaged')]\nplt.legend(handles=legend_elements)\n\nplt.tight_layout()\nplt.show()\n\nprint(\"Bar graph showing detection results completed\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Plot Score Distributions\n",
    "\n",
    "**Plot distribution of scores using KDE**\n",
    "\n",
    "Use kernel density estimation to visualize the probability distributions of scores for undamaged vs. damaged conditions. This helps assess the separability of the two classes.\n",
    "\n",
    "Parameters:\n",
    "- `flip_signs=True`: Ensure higher scores indicate more anomalous behavior\n",
    "- `use_log_scores=True`: Use logarithmic scale for better visualization\n",
    "- `smoothing=0.1`: Bandwidth parameter for kernel density estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Plot score distributions using KDE\nflip_signs = True\nuse_log_scores = True\nsmoothing = 0.1\n\n# Process scores\nscores_processed = -scores.flatten() if flip_signs else scores.flatten()\nif use_log_scores and np.min(scores_processed) > 0:\n    scores_processed = np.log10(scores_processed)\nelif use_log_scores and np.max(scores_processed) < 0:\n    scores_processed = -np.log10(-scores_processed)\n\n# Plot distributions using the function we implemented\naxes_handle = plot_score_distributions_shm(\n    scores_processed,\n    damage_states.flatten(),  # Convert from (N, 1) to (N,) shape\n    state_names=['Undamaged', 'Damaged'],\n    thresholds=None,\n    flip_signs=False,  # Already processed\n    use_log_scores=False,  # Already processed\n    smoothing=smoothing,\n    axes=None\n)\n\nplt.title('Score Distributions (Undamaged vs Damaged)', fontsize=14, fontweight='bold')\nxlabel_text = 'Log Mahalanobis Distance' if use_log_scores else 'Mahalanobis Distance'\nplt.xlabel(xlabel_text)\nplt.ylabel('Probability Density')\nplt.tight_layout()\nplt.show()\n\nprint(\"Score distribution visualization completed\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Receiver Operating Characteristic\n",
    "\n",
    "**Receiver operating characteristic (ROC) curve**\n",
    "\n",
    "Calculate the ROC curve to quantify the detection performance. The ROC curve shows the trade-off between:\n",
    "\n",
    "- **True Positive Rate (TPR)**: Sensitivity = TP/(TP+FN)\n",
    "- **False Positive Rate (FPR)**: 1-Specificity = FP/(FP+TN)\n",
    "\n",
    "A perfect detector would have TPR=1 and FPR=0 (upper-left corner). The Area Under the Curve (AUC) provides a single performance metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Calculate ROC curve\nTPR, FPR = roc_shm(\n    scores.flatten(),           # Convert from (N, 1) to (N,) shape\n    damage_states.flatten(),    # Convert from (N, 1) to (N,) shape\n    num_pts=None,              # Use default number of points\n    threshold_type=\"below\"     # Use below threshold (default)\n)\n\nprint(f\"ROC curve calculated:\")\nprint(f\"TPR shape: {TPR.shape}\")\nprint(f\"FPR shape: {FPR.shape}\")\nprint(f\"Number of threshold points: {len(TPR)}\")\n\n# Calculate AUC using trapezoidal rule\nauc = np.trapz(TPR, FPR)\nprint(f\"Area Under Curve (AUC): {auc:.4f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Plot Receiver Operating Characteristic Curve\n",
    "\n",
    "**Plot receiver operating characteristic curve**\n",
    "\n",
    "Visualize the ROC curve to assess detection performance. The curve shows how well the Mahalanobis distance can distinguish between undamaged and damaged conditions.\n",
    "\n",
    "- **Diagonal line**: Random classifier performance (AUC = 0.5)\n",
    "- **Upper-left corner**: Perfect classifier performance (AUC = 1.0)\n",
    "- **AUC > 0.7**: Generally considered acceptable performance\n",
    "- **AUC > 0.8**: Good performance\n",
    "- **AUC > 0.9**: Excellent performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Plot ROC curve\nplt.figure(figsize=(8, 6))\nplt.plot(FPR, TPR, 'b-', linewidth=2, label=f'ROC Curve (AUC = {auc:.3f})')\nplt.plot([0, 1], [0, 1], 'r--', linewidth=1, label='Random Classifier')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title(f'ROC Curve (AUC = {auc:.3f})', fontsize=14, fontweight='bold')\nplt.grid(True, alpha=0.3)\nplt.legend()\nplt.tight_layout()\nplt.show()\n\nprint(f\"ROC curve visualization completed\")\nprint(f\"Final AUC: {auc:.4f}\")\n\n# Performance interpretation\nif auc > 0.9:\n    performance = \"Excellent\"\nelif auc > 0.8:\n    performance = \"Good\"\nelif auc > 0.7:\n    performance = \"Acceptable\"\nelse:\n    performance = \"Poor\"\n    \nprint(f\"Detection performance: {performance} (AUC = {auc:.3f})\")\n\n# Update the summary with the actual AUC\nprint(f\"\\n=== LADPackage Outlier Detection Summary ===\")\nprint(f\"AUC Score: {auc:.3f} ({performance})\")\nprint(f\"Undamaged instances: {np.sum(damage_states == 0)}\")\nprint(f\"Damaged instances: {np.sum(damage_states == 1)}\")\nprint(f\"Training instances: {len(training_indices)}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This LADPackage outlier detection workflow successfully demonstrated:\n",
    "\n",
    "1. **Data Import**: Loaded 3-story structure data with 170 instances (90 undamaged, 80 damaged)\n",
    "2. **Feature Extraction**: Extracted AR model parameters (order 10) as damage-sensitive features\n",
    "3. **Feature Analysis**: Visualized feature variations across different structural conditions\n",
    "4. **Outlier Detection**: Applied Mahalanobis distance using training data from undamaged conditions\n",
    "5. **Performance Evaluation**: Achieved AUC = {auc:.3f} indicating {performance.lower()} detection performance\n",
    "\n",
    "### Key Insights\n",
    "\n",
    "- **AR parameters** effectively capture structural dynamics changes due to damage\n",
    "- **Mahalanobis distance** accounts for feature correlations, improving detection sensitivity\n",
    "- **Training on undamaged data** provides a robust baseline for anomaly detection\n",
    "- **ROC analysis** quantifies the trade-off between detection sensitivity and false alarms\n",
    "\n",
    "### Applications\n",
    "\n",
    "This methodology is applicable to:\n",
    "- **Civil structures**: Buildings, bridges, offshore platforms\n",
    "- **Mechanical systems**: Rotating machinery, aerospace components\n",
    "- **Infrastructure monitoring**: Real-time health assessment systems\n",
    "\n",
    "The workflow demonstrates the power of combining time series modeling (AR) with statistical outlier detection (Mahalanobis) for effective structural health monitoring."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}