{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Outlier Detection Based on Mahalanobis Distance\n\n## Introduction\n\nThe goal of this example is to discriminate undamaged and damaged structural state conditions based on outlier detection. The parameters from an autoregressive (AR) model are used as damage-sensitive features and a machine learning algorithm based on the Mahalanobis distance is used to create damage indicators (DIs) invariant for feature vectors from normal structural condition and that increase when feature vectors are from damaged structural conditions.\n\nData sets of an array of sensors from Channel 2-5 of the base-excited three story structure are used in this example. More details about the data sets can be found in the [3-Story Data Sets documentation](https://www.lanl.gov/projects/ei).\n\nThis example demonstrates:\n1. **Data Loading**: 3-story structure dataset with 4 channels, multiple conditions  \n2. **Feature Extraction**: AR(15) model parameters from channels 2-5 (not RMSE as in PCA example)\n3. **Train/Test Split**: Training on conditions 1-9, testing on conditions 1-9 (baseline) + 10-17 (damage)\n4. **Mahalanobis Modeling**: Learn mean and covariance from training features\n5. **Damage Detection**: Score test data and apply 95% threshold for classification\n6. **Visualization**: Time histories, feature plots, damage indicator bar charts\n\n**References:**\n\nWorden, K., & Manson, G. (2000). Damage Detection using Outlier Analysis. Journal of Sound and Vibration, 229 (3), 647-667.\n\n**SHMTools functions used:**\n- `ar_model_shm`\n- `learn_mahalanobis_shm`\n- `score_mahalanobis_shm`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import numpy as np\nimport matplotlib.pyplot as plt\n\n# Import shmtools (installed package)\nfrom shmtools.utils.data_loading import load_3story_data\nfrom shmtools.features.time_series import ar_model_shm\nfrom shmtools.classification.outlier_detection import learn_mahalanobis_shm, score_mahalanobis_shm\n\n# Set up plotting\nplt.style.use('default')\nplt.rcParams['figure.figsize'] = (12, 8)\nplt.rcParams['font.size'] = 10"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Raw Data\n",
    "\n",
    "Load the 3-story structure dataset and extract channels 2-5 for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data set\n",
    "data_dict = load_3story_data()\n",
    "dataset = data_dict['dataset']\n",
    "fs = data_dict['fs']\n",
    "channels = data_dict['channels']\n",
    "damage_states = data_dict['damage_states']\n",
    "\n",
    "print(f\"Dataset shape: {dataset.shape}\")\n",
    "print(f\"Sampling frequency: {fs} Hz\")\n",
    "print(f\"Channels: {channels}\")\n",
    "print(f\"Number of damage states: {len(np.unique(damage_states))}\")\n",
    "\n",
    "# Extract channels 2-5 (indices 1-4 in Python)\n",
    "data = dataset[:, 1:5, :]\n",
    "t, m, n = data.shape\n",
    "\n",
    "print(f\"\\nData for analysis:\")\n",
    "print(f\"Time points: {t}\")\n",
    "print(f\"Channels: {m} (Ch2-Ch5)\")\n",
    "print(f\"Conditions: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Time History from Baseline and Damaged Conditions\n",
    "\n",
    "The figure below plots time histories from State#1 (baseline condition, black) and State#16 (damaged with simulated operational changes, red) in concatenated format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Channel labels\n",
    "labels = ['Channel 2', 'Channel 3', 'Channel 4', 'Channel 5']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "time_1 = np.arange(1, t+1)\n",
    "time_2 = np.arange(t+1, 2*t+1)\n",
    "\n",
    "for i in range(m):\n",
    "    # State #1 (condition index 0) and State #16 (condition index 150)\n",
    "    baseline_signal = data[:, i, 0]   # First condition (State 1)\n",
    "    damaged_signal = data[:, i, 150]  # Condition 151 (State 16, damaged with operational changes)\n",
    "    \n",
    "    axes[i].plot(time_1, baseline_signal, 'k-', label='State #1 (Baseline)', linewidth=0.8)\n",
    "    axes[i].plot(time_2, damaged_signal, 'r--', label='State #16 (Damage)', linewidth=0.8)\n",
    "    \n",
    "    axes[i].set_title(labels[i])\n",
    "    axes[i].set_ylim([-2.5, 2.5])\n",
    "    axes[i].set_xlim([1, 2*t])\n",
    "    axes[i].set_yticks([-2, 0, 2])\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "    \n",
    "    if i >= 2:  # Bottom row\n",
    "        axes[i].set_xlabel('Data Points')\n",
    "    if i % 2 == 0:  # Left column\n",
    "        axes[i].set_ylabel('Acceleration (g)')\n",
    "    \n",
    "    if i == 0:  # Add legend to first subplot\n",
    "        axes[i].legend(loc='upper right', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction of Damage-Sensitive Features\n",
    "\n",
    "This section estimates the AR(15) model parameters from the time histories of Channels 2-5 and plots the feature vectors for each instance (or condition). **Note**: Unlike the PCA example, this uses AR parameters directly as features, not the RMSE values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# AR model order\nar_order = 15\n\nprint(f\"Extracting AR({ar_order}) model parameters as features...\")\n\n# Estimation of AR Parameters (we need the parameters, not RMSE)\nar_parameters_fv, rmse_fv, ar_parameters, ar_residuals, ar_prediction = ar_model_shm(data, ar_order)\n\nprint(f\"AR parameters FV shape: {ar_parameters_fv.shape}\")\nprint(f\"RMSE shape: {rmse_fv.shape}\")\nprint(f\"AR parameters shape: {ar_parameters.shape}\")\n\n# Use AR parameters as features (not RMSE as in PCA example)\nfeatures = ar_parameters_fv  # Shape: (instances, features) where features = channels * ar_order\nprint(f\"Features shape: {features.shape} (instances, channels*ar_order)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Training and Test Data\n",
    "\n",
    "Following the original MATLAB example exactly:\n",
    "- **Training Data**: From conditions 1-9 (first 9 from each of the first 9 damage states)\n",
    "- **Test Data**: Every 10th condition from all damage states (conditions 10, 20, 30, ..., 170)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Data - following MATLAB exactly\n",
    "# for i=1:9; learnData(i*9-8:i*9,:)=arParameters(i*10-9:i*10-1,:); end\n",
    "num_features = features.shape[1]\n",
    "learn_data = np.zeros((9*9, num_features))  # 81 samples x (4 channels * 15 AR params)\n",
    "\n",
    "for i in range(1, 10):  # i = 1 to 9\n",
    "    start_idx = i*9 - 8 - 1  # Convert to 0-based indexing\n",
    "    end_idx = i*9 - 1\n",
    "    \n",
    "    features_start_idx = i*10 - 9 - 1  # Convert to 0-based indexing  \n",
    "    features_end_idx = i*10 - 1 - 1\n",
    "    \n",
    "    learn_data[start_idx:end_idx+1, :] = features[features_start_idx:features_end_idx+1, :]\n",
    "\n",
    "# Test Data - every 10th condition\n",
    "# scoreData=arParameters(10:10:170,:)\n",
    "test_indices = np.arange(9, 170, 10)  # 10:10:170 in MATLAB (0-based: 9:10:169)\n",
    "score_data = features[test_indices, :]\n",
    "\n",
    "print(f\"Training data shape: {learn_data.shape}\")\n",
    "print(f\"Test data shape: {score_data.shape}\")\n",
    "print(f\"Test indices (MATLAB 1-based): {test_indices + 1}\")\n",
    "\n",
    "n_test = score_data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Test Data Features\n",
    "\n",
    "Visualization of the extracted AR parameter features showing the feature vectors composed of AR parameters from Channel 2-5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Plot test data (following MATLAB exactly)\nplt.figure(figsize=(12, 6))\n\n# Get dimensions: n = instances, m = features\nn_test_plot, m = score_data.shape\n\n# MATLAB: plot(1:m,scoreData(1:9,:)','k',1:m,scoreData(10:17,:)','r')\n# Let's try the transpose approach but plot each COLUMN of the transposed matrix\n\n# X-axis: feature indices (1 to m)\nfeature_indices = np.arange(1, m + 1)\n\n# MATLAB scoreData(1:9,:)' creates a (m x 9) matrix, then plots each column as a line\nundamaged_transposed = score_data[:9, :].T  # Shape: (60, 9)\ndamaged_transposed = score_data[9:17, :].T  # Shape: (60, 8)\n\n# Plot each column of the transposed matrices\nfor i in range(undamaged_transposed.shape[1]):  # 9 undamaged instances\n    plt.plot(feature_indices, undamaged_transposed[:, i], 'k-', linewidth=1, alpha=0.7)\n\nfor i in range(damaged_transposed.shape[1]):  # 8 damaged instances  \n    plt.plot(feature_indices, damaged_transposed[:, i], 'r-', linewidth=1, alpha=0.7)\n\nplt.title('Feature Vectors Compose of AR Parameters from Channel2-5')\nplt.xlabel('AR Parameters in Concatenated Format')\nplt.ylabel('Amplitude')\nplt.xlim([1, m])\nplt.ylim([-8, 8])\n\n# Add legend (MATLAB style)\n# Create dummy lines for legend\nimport matplotlib.lines as mlines\nundamaged_line = mlines.Line2D([], [], color='k', label='Undamaged')\ndamaged_line = mlines.Line2D([], [], color='r', label='Damaged')\nplt.legend(handles=[undamaged_line, damaged_line])\n\nplt.grid(True, alpha=0.3)\n\n# Add vertical separator lines (MATLAB: m/4, m/4*2, m/4*3)\nfor i in range(1, 4):\n    plt.axvline(x=m/4 * i, color='k', linestyle='-.', alpha=0.5)\n\n# Add channel labels (following MATLAB text positions)\n# MATLAB positions: 4, 18, 33, 48 for channels 2-5\nplt.text(4, -7, 'Channel 2', ha='center', va='top', \n         bbox=dict(boxstyle='round', facecolor='white', edgecolor='k', alpha=0.8))\nplt.text(18, -7, 'Channel 3', ha='center', va='top',\n         bbox=dict(boxstyle='round', facecolor='white', edgecolor='k', alpha=0.8))\nplt.text(33, -7, 'Channel 4', ha='center', va='top',\n         bbox=dict(boxstyle='round', facecolor='white', edgecolor='k', alpha=0.8))\nplt.text(48, -7, 'Channel 5', ha='center', va='top',\n         bbox=dict(boxstyle='round', facecolor='white', edgecolor='k', alpha=0.8))\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Modeling for Feature Classification\n",
    "\n",
    "The Mahalanobis-based machine learning algorithm is used to normalize the features and reduce each feature vector into a score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Learn Mahalanobis model from training data\nprint(\"Learning Mahalanobis model from training data...\")\nmodel = learn_mahalanobis_shm(learn_data)\n\nprint(f\"Mahalanobis model mean shape: {model['dataMean'].shape}\")\nprint(f\"Mahalanobis model covariance shape: {model['dataCov'].shape}\")\n\n# Score test data using the learned model\nprint(\"\\nScoring test data...\")\nDI = score_mahalanobis_shm(score_data, model)\n\nprint(f\"Damage indicators shape: {DI.shape}\")\nprint(f\"\\nDamage indicators (first 10): {DI[:10].flatten()}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier Detection\n",
    "\n",
    "Threshold determination based on the 95% cut-off over the training data and visualization of damage indicators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Threshold based on the 95% cut-off over the training data\nprint(\"Computing threshold from training data...\")\nthreshold_scores = score_mahalanobis_shm(learn_data, model)\nthreshold_sorted = np.sort(-threshold_scores.flatten())  # Sort negative scores (following MATLAB)\n\n# MATLAB: UCL=threshold(round(length(threshold)*0.95));\n# In MATLAB (1-indexed): round(81*0.95) = round(76.95) = 77, so threshold(77)\n# In Python (0-indexed): we want index 76, so threshold_sorted[76]\nmatlab_index = int(np.round(len(threshold_sorted) * 0.95))  # This gives 77 (MATLAB 1-based)\npython_index = matlab_index - 1  # Convert to 0-based: 77-1=76\nUCL = threshold_sorted[python_index]\n\nprint(f\"Upper Control Limit (UCL): {UCL:.6f}\")\nprint(f\"Number of training samples: {len(threshold_scores)}\")\nprint(f\"MATLAB index (1-based): {matlab_index}\")\nprint(f\"Python index (0-based): {python_index}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Damage Indicators\n",
    "\n",
    "The figure below shows that the approach for damage detection, based on Mahalanobis distance along with the AR(15) parameters from Channel 2-5, is able to discriminate all the undamaged (1-9) and damaged (10-17) state conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot DIs\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "state_conditions = np.arange(1, n_test + 1)\n",
    "\n",
    "# Undamaged conditions (1-9)\n",
    "plt.bar(state_conditions[:9], -DI[:9].flatten(), color='k', alpha=0.7, label='Undamaged')\n",
    "\n",
    "# Damaged conditions (10-17)\n",
    "plt.bar(state_conditions[9:17], -DI[9:17].flatten(), color='r', alpha=0.7, label='Damaged')\n",
    "\n",
    "plt.title('Damage Indicators from the Test Data')\n",
    "plt.xlim([0, n_test + 1])\n",
    "plt.xticks(state_conditions)\n",
    "plt.xlabel('State Condition [Undamaged(1-9) and Damaged (10-17)]')\n",
    "plt.ylabel('DI')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add threshold line\n",
    "plt.axhline(y=UCL, color='b', linestyle='-.', linewidth=2, label=f'95% Threshold ({UCL:.4f})')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print classification results\n",
    "print(\"\\nClassification Results:\")\n",
    "print(\"=\" * 50)\n",
    "for i in range(n_test):\n",
    "    state_type = \"Undamaged\" if i < 9 else \"Damaged\"\n",
    "    detected = \"DAMAGE\" if -DI[i, 0] > UCL else \"normal\"\n",
    "    status = \"✓\" if (i < 9 and detected == \"normal\") or (i >= 9 and detected == \"DAMAGE\") else \"✗\"\n",
    "    print(f\"State {i+1:2d} ({state_type:9s}): DI = {-DI[i, 0]:8.4f} → {detected:6s} {status}\")\n",
    "\n",
    "# Calculate performance metrics\n",
    "undamaged_correct = np.sum(-DI[:9, 0] <= UCL)\n",
    "damaged_correct = np.sum(-DI[9:17, 0] > UCL)\n",
    "total_correct = undamaged_correct + damaged_correct\n",
    "\n",
    "print(f\"\\nPerformance Summary:\")\n",
    "print(f\"Undamaged correctly classified: {undamaged_correct}/9\")\n",
    "print(f\"Damaged correctly classified: {damaged_correct}/8\")\n",
    "print(f\"Overall accuracy: {total_correct}/{n_test} ({100*total_correct/n_test:.1f}%)\")\n",
    "print(f\"False positives: {9 - undamaged_correct}\")\n",
    "print(f\"False negatives: {8 - damaged_correct}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This example demonstrated the complete Mahalanobis distance-based outlier detection workflow for structural health monitoring:\n",
    "\n",
    "1. **Data Loading**: Successfully loaded the 3-story structure dataset\n",
    "2. **Feature Extraction**: Used AR(15) model parameters as damage-sensitive features (different from PCA example)\n",
    "3. **Mahalanobis Modeling**: Learned mean vector and covariance matrix from baseline training data\n",
    "4. **Damage Detection**: Applied Mahalanobis distance-based scoring with 95% threshold\n",
    "5. **Classification**: Achieved excellent separation between undamaged and damaged conditions\n",
    "\n",
    "The results show that the Mahalanobis distance-based approach successfully discriminates between undamaged (states 1-9) and damaged (states 10-17) conditions using AR model parameters as features.\n",
    "\n",
    "**Key differences from PCA approach:**\n",
    "- Uses AR parameters directly as features (not RMSE values)\n",
    "- Computes Mahalanobis distance instead of PCA reconstruction error\n",
    "- Simpler statistical model (mean + covariance vs. principal components)\n",
    "- More direct interpretation of feature importance\n",
    "\n",
    "**Key advantages of Mahalanobis distance:**\n",
    "- Accounts for feature correlations through covariance matrix\n",
    "- Scale-invariant distance metric\n",
    "- Well-established statistical foundation\n",
    "- Computationally efficient\n",
    "- Robust to multivariate outliers when training data is clean\n",
    "\n",
    "**See also:**\n",
    "- [Outlier Detection based on Principal Component Analysis](pca_outlier_detection.ipynb)\n",
    "- [Outlier Detection based on the Singular Value Decomposition](svd_outlier_detection.ipynb)\n",
    "- [Outlier Detection based on the Factor Analysis Model](factor_analysis_outlier_detection.ipynb)\n",
    "- [Outlier Detection based on Nonlinear Principal Component Analysis](nlpca_outlier_detection.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}