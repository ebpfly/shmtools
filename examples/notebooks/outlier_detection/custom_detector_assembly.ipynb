{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Detector Assembly\n",
    "\n",
    "This notebook demonstrates how to assemble custom outlier detectors by mixing and matching learning/scoring function pairs from different detector categories. The custom detector assembly framework allows you to:\n",
    "\n",
    "1. **Parametric Detectors**: PCA, Mahalanobis, SVD, Factor Analysis\n",
    "2. **Non-parametric Detectors**: Kernel density estimation with various kernels\n",
    "3. **Semi-parametric Detectors**: Gaussian Mixture Models with partitioning algorithms\n",
    "\n",
    "## Overview\n",
    "\n",
    "The `assemble_outlier_detector_shm` function provides an interactive framework for creating custom detectors. You can:\n",
    "- Select from pre-built detector combinations\n",
    "- Configure parameters for each detector type\n",
    "- Generate custom training functions that work with the universal `detect_outlier_shm` interface\n",
    "- Save and load detector configurations for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as npimport matplotlib.pyplot as plt# Import shmtools (installed package)from examples.data import import_3story_structure_shmfrom shmtools.features import ar_model_shmfrom shmtools.classification import (# Set up plottingplt.style.use('default')plt.rcParams['figure.figsize'] = (12, 8)plt.rcParams['font.size'] = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare Data\n",
    "\n",
    "We'll use the 3-story structure dataset and extract AR model features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load the 3-story structure dataset\ndataset, damage_states_raw, state_list = import_3story_structure_shm()\n# Convert state_list to match expected format (flatten and convert to int)\ndamage_states = state_list.flatten().astype(int)\n\n# Extract channels 2-5 (accelerations) - skip channel 0 (force)\nacceleration_data = dataset[:, 1:, :]\nprint(f\"Data shape: {acceleration_data.shape} (time_points, channels, instances)\")\n\n# Extract AR model features\nar_order = 15\nar_features, _, _, _, _ = ar_model_shm(acceleration_data, ar_order)\nprint(f\"AR features shape: {ar_features.shape} (instances, features)\")\n\n# Separate undamaged and damaged data\nundamaged_mask = damage_states <= 9\ndamaged_mask = damage_states > 9\n\nundamaged_features = ar_features[undamaged_mask]\ndamaged_features = ar_features[damaged_mask]\n\nprint(f\"\\nUndamaged instances: {undamaged_features.shape[0]}\")\nprint(f\"Damaged instances: {damaged_features.shape[0]}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Available Detectors\n",
    "\n",
    "Let's see what detectors are available in each category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display available detectors from the registry\n",
    "print(\"=== PARAMETRIC DETECTORS ===\")\n",
    "for name, info in detector_registry.parametric_detectors.items():\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Display Name: {info['display_name']}\")\n",
    "    print(f\"  Description: {info['description']}\")\n",
    "    print(f\"  Learn Function: {info['learn_function']}\")\n",
    "    print(f\"  Score Function: {info['score_function']}\")\n",
    "\n",
    "print(\"\\n=== NON-PARAMETRIC DETECTORS ===\")\n",
    "for name, info in detector_registry.nonparametric_detectors.items():\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Display Name: {info['display_name']}\")\n",
    "    print(f\"  Description: {info['description']}\")\n",
    "    print(f\"  Available Kernels: {', '.join(detector_registry.available_kernels)}\")\n",
    "\n",
    "print(\"\\n=== SEMI-PARAMETRIC DETECTORS ===\")\n",
    "for name, info in detector_registry.semiparametric_detectors.items():\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Display Name: {info['display_name']}\")\n",
    "    print(f\"  Description: {info['description']}\")\n",
    "    print(f\"  Partitioning Algorithms: {', '.join(detector_registry.partitioning_algorithms)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Assemble a Parametric Detector (PCA)\n",
    "\n",
    "First, let's assemble a PCA-based detector programmatically (non-interactive mode):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble a PCA detector with custom parameters\n",
    "pca_detector = assemble_outlier_detector_shm(\n",
    "    suffix=\"PCA_Custom\",\n",
    "    detector_type=\"parametric\",\n",
    "    detector_name=\"pca\",\n",
    "    parameters={\n",
    "        \"per_var\": 0.95,  # Retain 95% of variance\n",
    "        \"stand\": 0        # Use standardization\n",
    "    },\n",
    "    interactive=False\n",
    ")\n",
    "\n",
    "print(\"Assembled PCA Detector:\")\n",
    "print(f\"  Type: {pca_detector['type']}\")\n",
    "print(f\"  Name: {pca_detector['name']}\")\n",
    "print(f\"  Learn Function: {pca_detector['learn_function']}\")\n",
    "print(f\"  Score Function: {pca_detector['score_function']}\")\n",
    "print(f\"  Parameters: {pca_detector['parameters']}\")\n",
    "print(f\"  Training Function: {pca_detector['training_function'].__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the Assembled PCA Detector\n",
    "\n",
    "Now let's use the assembled detector to train and test on our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data for training and testing\n",
    "train_split = 0.8\n",
    "n_train = int(train_split * len(undamaged_features))\n",
    "\n",
    "# Training data: 80% of undamaged\n",
    "train_features = undamaged_features[:n_train]\n",
    "\n",
    "# Test data: 20% undamaged + all damaged\n",
    "test_features = np.vstack([\n",
    "    undamaged_features[n_train:],\n",
    "    damaged_features\n",
    "])\n",
    "\n",
    "# Create labels for test data\n",
    "test_labels = np.concatenate([\n",
    "    np.zeros(len(undamaged_features[n_train:])),  # Undamaged = 0\n",
    "    np.ones(len(damaged_features))                # Damaged = 1\n",
    "]).astype(int)\n",
    "\n",
    "print(f\"Training samples: {len(train_features)}\")\n",
    "print(f\"Test samples: {len(test_features)} ({np.sum(test_labels == 0)} undamaged, {np.sum(test_labels == 1)} damaged)\")\n",
    "\n",
    "# Train using the assembled detector's training function\n",
    "models = pca_detector['training_function'](\n",
    "    train_features,\n",
    "    k=5,\n",
    "    confidence=0.95,\n",
    "    model_filename=\"assembled_pca_model.pkl\"\n",
    ")\n",
    "\n",
    "# Detect outliers\n",
    "results, confidences, scores, threshold = detect_outlier_shm(\n",
    "    test_features,\n",
    "    models=models\n",
    ")\n",
    "\n",
    "# Calculate performance metrics\n",
    "accuracy = np.mean(results == test_labels)\n",
    "false_positive_rate = np.mean(results[test_labels == 0] == 1)\n",
    "false_negative_rate = np.mean(results[test_labels == 1] == 0)\n",
    "\n",
    "print(f\"\\nPerformance Metrics:\")\n",
    "print(f\"  Accuracy: {accuracy:.3f}\")\n",
    "print(f\"  False Positive Rate: {false_positive_rate:.3f}\")\n",
    "print(f\"  False Negative Rate: {false_negative_rate:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Assemble a Non-Parametric Detector (Kernel Density)\n",
    "\n",
    "Let's assemble a kernel density detector with Epanechnikov kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble a kernel density detector\n",
    "kde_detector = assemble_outlier_detector_shm(\n",
    "    suffix=\"KDE_Epanechnikov\",\n",
    "    detector_type=\"nonparametric\",\n",
    "    detector_name=\"kernel_density\",\n",
    "    parameters={\n",
    "        \"kernel_function\": \"epanechnikov\",\n",
    "        \"bandwidth_method\": \"scott\"  # Use Scott's rule for bandwidth\n",
    "    },\n",
    "    interactive=False\n",
    ")\n",
    "\n",
    "print(\"Assembled KDE Detector:\")\n",
    "print(f\"  Type: {kde_detector['type']}\")\n",
    "print(f\"  Name: {kde_detector['name']}\")\n",
    "print(f\"  Parameters: {kde_detector['parameters']}\")\n",
    "\n",
    "# Train and test with KDE detector\n",
    "kde_models = kde_detector['training_function'](\n",
    "    train_features,\n",
    "    k=3,\n",
    "    confidence=0.95,\n",
    "    model_filename=\"assembled_kde_model.pkl\"\n",
    ")\n",
    "\n",
    "# Detect outliers\n",
    "kde_results, kde_confidences, kde_scores, kde_threshold = detect_outlier_shm(\n",
    "    test_features,\n",
    "    models=kde_models\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Assemble a Semi-Parametric Detector (GMM)\n",
    "\n",
    "Let's assemble a GMM-based semi-parametric detector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble a GMM semi-parametric detector\n",
    "gmm_detector = assemble_outlier_detector_shm(\n",
    "    suffix=\"GMM_KMeans\",\n",
    "    detector_type=\"semiparametric\",\n",
    "    detector_name=\"gmm_semi\",\n",
    "    parameters={\n",
    "        \"partitioning_algorithm\": \"kmeans\",\n",
    "        \"n_components\": 5\n",
    "    },\n",
    "    interactive=False\n",
    ")\n",
    "\n",
    "print(\"Assembled GMM Detector:\")\n",
    "print(f\"  Type: {gmm_detector['type']}\")\n",
    "print(f\"  Name: {gmm_detector['name']}\")\n",
    "print(f\"  Parameters: {gmm_detector['parameters']}\")\n",
    "\n",
    "# Train and test with GMM detector\n",
    "gmm_models = gmm_detector['training_function'](\n",
    "    train_features,\n",
    "    k=5,\n",
    "    confidence=0.95,\n",
    "    model_filename=\"assembled_gmm_model.pkl\",\n",
    "    dist_for_scores=\"norm\"  # Use normal distribution for threshold\n",
    ")\n",
    "\n",
    "# Detect outliers\n",
    "gmm_results, gmm_confidences, gmm_scores, gmm_threshold = detect_outlier_shm(\n",
    "    test_features,\n",
    "    models=gmm_models\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Detector Performance\n",
    "\n",
    "Let's compare the performance of all three assembled detectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ROC curves for all detectors\n",
    "pca_tpr, pca_fpr = roc_shm(scores, test_labels)\n",
    "kde_tpr, kde_fpr = roc_shm(kde_scores, test_labels)\n",
    "gmm_tpr, gmm_fpr = roc_shm(gmm_scores, test_labels)\n",
    "\n",
    "# Plot ROC curves\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Calculate AUC using trapezoidal rule\n",
    "pca_auc = -np.trapz(pca_tpr, pca_fpr)\n",
    "kde_auc = -np.trapz(kde_tpr, kde_fpr)\n",
    "gmm_auc = -np.trapz(gmm_tpr, gmm_fpr)\n",
    "\n",
    "plt.plot(pca_fpr, pca_tpr, 'b-', linewidth=2, label=f'PCA (AUC = {pca_auc:.3f})')\n",
    "plt.plot(kde_fpr, kde_tpr, 'r-', linewidth=2, label=f'KDE (AUC = {kde_auc:.3f})')\n",
    "plt.plot(gmm_fpr, gmm_tpr, 'g-', linewidth=2, label=f'GMM (AUC = {gmm_auc:.3f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', alpha=0.5, label='Random Classifier')\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves for Assembled Detectors')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.show()\n",
    "\n",
    "# Performance summary table\n",
    "print(\"\\n=== PERFORMANCE SUMMARY ===\")\n",
    "print(f\"{'Detector':<15} {'Accuracy':<10} {'FPR':<10} {'FNR':<10} {'AUC':<10}\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "# PCA performance\n",
    "pca_acc = np.mean(results == test_labels)\n",
    "pca_fpr_val = np.mean(results[test_labels == 0] == 1)\n",
    "pca_fnr = np.mean(results[test_labels == 1] == 0)\n",
    "print(f\"{'PCA':<15} {pca_acc:<10.3f} {pca_fpr_val:<10.3f} {pca_fnr:<10.3f} {pca_auc:<10.3f}\")\n",
    "\n",
    "# KDE performance\n",
    "kde_acc = np.mean(kde_results == test_labels)\n",
    "kde_fpr_val = np.mean(kde_results[test_labels == 0] == 1)\n",
    "kde_fnr = np.mean(kde_results[test_labels == 1] == 0)\n",
    "print(f\"{'KDE':<15} {kde_acc:<10.3f} {kde_fpr_val:<10.3f} {kde_fnr:<10.3f} {kde_auc:<10.3f}\")\n",
    "\n",
    "# GMM performance\n",
    "gmm_acc = np.mean(gmm_results == test_labels)\n",
    "gmm_fpr_val = np.mean(gmm_results[test_labels == 0] == 1)\n",
    "gmm_fnr = np.mean(gmm_results[test_labels == 1] == 0)\n",
    "print(f\"{'GMM':<15} {gmm_acc:<10.3f} {gmm_fpr_val:<10.3f} {gmm_fnr:<10.3f} {gmm_auc:<10.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and Load Detector Configurations\n",
    "\n",
    "Detector assemblies can be saved and loaded for reproducibility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save detector configurations\n",
    "save_detector_assembly(pca_detector, \"pca_detector_config.json\")\n",
    "save_detector_assembly(kde_detector, \"kde_detector_config.json\")\n",
    "save_detector_assembly(gmm_detector, \"gmm_detector_config.json\")\n",
    "\n",
    "print(\"Detector configurations saved!\")\n",
    "\n",
    "# Load a detector configuration\n",
    "loaded_pca = load_detector_assembly(\"pca_detector_config.json\")\n",
    "\n",
    "print(\"\\nLoaded PCA detector configuration:\")\n",
    "print(f\"  Type: {loaded_pca['type']}\")\n",
    "print(f\"  Name: {loaded_pca['name']}\")\n",
    "print(f\"  Parameters: {loaded_pca['parameters']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Assembly Example\n",
    "\n",
    "For interactive assembly (when `interactive=True`), the function will prompt you for:\n",
    "1. Detector type selection\n",
    "2. Specific detector algorithm selection\n",
    "3. Parameter configuration\n",
    "\n",
    "This is useful for exploring different detector configurations without writing code.\n",
    "\n",
    "```python\n",
    "# Example of interactive assembly (commented out for notebook execution)\n",
    "# interactive_detector = assemble_outlier_detector_shm(interactive=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Score Distributions\n",
    "\n",
    "Let's visualize how different detectors score the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# PCA scores\n",
    "axes[0].hist(scores[test_labels == 0], bins=30, alpha=0.7, density=True, label='Undamaged')\n",
    "axes[0].hist(scores[test_labels == 1], bins=30, alpha=0.7, density=True, label='Damaged')\n",
    "axes[0].axvline(threshold, color='r', linestyle='--', label=f'Threshold = {threshold:.2f}')\n",
    "axes[0].set_xlabel('Score')\n",
    "axes[0].set_ylabel('Density')\n",
    "axes[0].set_title('PCA Detector Scores')\n",
    "axes[0].legend()\n",
    "\n",
    "# KDE scores\n",
    "axes[1].hist(kde_scores[test_labels == 0], bins=30, alpha=0.7, density=True, label='Undamaged')\n",
    "axes[1].hist(kde_scores[test_labels == 1], bins=30, alpha=0.7, density=True, label='Damaged')\n",
    "axes[1].axvline(kde_threshold, color='r', linestyle='--', label=f'Threshold = {kde_threshold:.2f}')\n",
    "axes[1].set_xlabel('Score')\n",
    "axes[1].set_ylabel('Density')\n",
    "axes[1].set_title('KDE Detector Scores')\n",
    "axes[1].legend()\n",
    "\n",
    "# GMM scores\n",
    "axes[2].hist(gmm_scores[test_labels == 0], bins=30, alpha=0.7, density=True, label='Undamaged')\n",
    "axes[2].hist(gmm_scores[test_labels == 1], bins=30, alpha=0.7, density=True, label='Damaged')\n",
    "axes[2].axvline(gmm_threshold, color='r', linestyle='--', label=f'Threshold = {gmm_threshold:.2f}')\n",
    "axes[2].set_xlabel('Score')\n",
    "axes[2].set_ylabel('Density')\n",
    "axes[2].set_title('GMM Detector Scores')\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Custom Detector Assembly**: How to create custom outlier detectors by combining different learning and scoring functions\n",
    "2. **Detector Categories**: Working with parametric (PCA), non-parametric (KDE), and semi-parametric (GMM) detectors\n",
    "3. **Parameter Configuration**: Setting specific parameters for each detector type\n",
    "4. **Performance Comparison**: Evaluating multiple detectors on the same dataset\n",
    "5. **Configuration Management**: Saving and loading detector configurations for reproducibility\n",
    "\n",
    "The custom detector assembly framework provides flexibility to:\n",
    "- Mix and match algorithms based on your specific application\n",
    "- Fine-tune parameters for optimal performance\n",
    "- Create reproducible detection workflows\n",
    "- Integrate seamlessly with the universal `detect_outlier_shm` interface\n",
    "\n",
    "This framework is particularly useful when:\n",
    "- Default detectors don't meet your specific requirements\n",
    "- You need to explore different algorithmic approaches\n",
    "- You want to create application-specific detection pipelines\n",
    "- Reproducibility and configuration management are important"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}