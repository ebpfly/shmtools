{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# AR Model Order Selection\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The goal of this example is to demonstrate various methods for selecting the optimal order of autoregressive (AR) models. AR model order selection is a critical step in time series analysis and feature extraction for structural health monitoring, as the model order directly affects the quality of the extracted features and subsequent damage detection performance.\n",
    "\n",
    "This example demonstrates five different methods for AR model order selection:\n",
    "\n",
    "1. **AIC (Akaike Information Criterion)** - Balances model fit vs. complexity\n",
    "2. **BIC (Bayesian Information Criterion)** - More conservative than AIC\n",
    "3. **PAF (Partial Autocorrelation Function)** - Based on statistical significance of AR parameters\n",
    "4. **SVD (Singular Value Decomposition)** - Analyzes rank structure of data matrix\n",
    "5. **RMS (Root Mean Square Error)** - Based on prediction error improvement\n",
    "\n",
    "Data from **Channel 5** of the base-excited three story structure is used in this example to demonstrate the different order selection approaches.\n",
    "\n",
    "**Key Applications:**\n",
    "- Optimal feature extraction for damage detection\n",
    "- Time series modeling and prediction\n",
    "- Signal compression and denoising\n",
    "- System identification in structural dynamics\n",
    "\n",
    "**SHMTools functions used:**\n",
    "- `ar_model_order`\n",
    "- `ar_model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add shmtools to path - handle different execution contexts (lesson from previous phases)\n",
    "current_dir = Path.cwd()\n",
    "notebook_dir = Path(__file__).parent if '__file__' in globals() else current_dir\n",
    "\n",
    "# Try different relative paths to find shmtools\n",
    "possible_paths = [\n",
    "    notebook_dir.parent.parent.parent,  # From examples/notebooks/basic/\n",
    "    current_dir.parent.parent,          # From examples/notebooks/\n",
    "    current_dir,                        # From project root\n",
    "    Path('/Users/eric/repo/shm/shmtools-python')  # Absolute fallback\n",
    "]\n",
    "\n",
    "shmtools_found = False\n",
    "for path in possible_paths:\n",
    "    if (path / 'shmtools').exists():\n",
    "        if str(path) not in sys.path:\n",
    "            sys.path.insert(0, str(path))\n",
    "        shmtools_found = True\n",
    "        print(f\"Found shmtools at: {path}\")\n",
    "        break\n",
    "\n",
    "if not shmtools_found:\n",
    "    print(\"Warning: Could not find shmtools module\")\n",
    "\n",
    "from shmtools.utils.data_loading import load_3story_data\n",
    "from shmtools.features.time_series import ar_model_order, ar_model\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## Load and Prepare Data\n",
    "\n",
    "Load the 3-story structure dataset and extract Channel 5 data from a baseline (undamaged) condition for AR model order analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data set\n",
    "data_dict = load_3story_data()\n",
    "dataset = data_dict['dataset']\n",
    "fs = data_dict['fs']\n",
    "channels = data_dict['channels']\n",
    "\n",
    "print(f\"Dataset shape: {dataset.shape}\")\n",
    "print(f\"Sampling frequency: {fs} Hz\")\n",
    "print(f\"Channels: {channels}\")\n",
    "\n",
    "# Extract Channel 5 data from first baseline condition (index 4 for channel, 0 for condition)\n",
    "channel_5_baseline = dataset[:, 4, 0]  # Shape: (8192,)\n",
    "t = len(channel_5_baseline)\n",
    "\n",
    "print(f\"\\nChannel 5 baseline data:\")\n",
    "print(f\"Time points: {t}\")\n",
    "print(f\"Mean: {np.mean(channel_5_baseline):.6f}\")\n",
    "print(f\"Std: {np.std(channel_5_baseline):.6f}\")\n",
    "print(f\"Min: {np.min(channel_5_baseline):.6f}\")\n",
    "print(f\"Max: {np.max(channel_5_baseline):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "### Plot Time Series Data\n",
    "\n",
    "Visualize the baseline acceleration time history from Channel 5 to understand the signal characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot time series\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "time_points = np.arange(1, t + 1)\n",
    "plt.plot(time_points, channel_5_baseline, 'k-', linewidth=0.8)\n",
    "plt.title('Channel 5 Baseline Acceleration Time History', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Time Points')\n",
    "plt.ylabel('Acceleration (g)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xlim([1, t])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show a zoomed view of the first 1000 points\n",
    "plt.figure(figsize=(14, 6))\n",
    "zoom_points = 1000\n",
    "plt.plot(time_points[:zoom_points], channel_5_baseline[:zoom_points], 'k-', linewidth=1.0)\n",
    "plt.title(f'Channel 5 Baseline - First {zoom_points} Points (Zoomed View)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Time Points')\n",
    "plt.ylabel('Acceleration (g)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xlim([1, zoom_points])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## AR Model Order Selection Methods\n",
    "\n",
    "Apply different methods to determine the optimal AR model order. Each method has different theoretical foundations and practical advantages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "max_order = 30\n",
    "methods = ['aic', 'bic', 'paf', 'svd', 'rms']\n",
    "tolerance = 0.078  # Tolerance for PAF and RMS methods\n",
    "\n",
    "# Store results\n",
    "results = {}\n",
    "criterion_values = {}\n",
    "\n",
    "print(f\"Testing AR model orders from 1 to {max_order}...\\n\")\n",
    "\n",
    "# Apply each method\n",
    "for method in methods:\n",
    "    print(f\"Applying {method.upper()} method...\")\n",
    "    \n",
    "    optimal_order, values = ar_model_order(\n",
    "        channel_5_baseline, \n",
    "        max_order=max_order, \n",
    "        method=method, \n",
    "        tolerance=tolerance\n",
    "    )\n",
    "    \n",
    "    results[method] = optimal_order\n",
    "    criterion_values[method] = values\n",
    "    \n",
    "    print(f\"  Optimal order: {optimal_order}\")\n",
    "    print()\n",
    "\n",
    "# Summary of results\n",
    "print(\"=\" * 50)\n",
    "print(\"AR MODEL ORDER SELECTION RESULTS\")\n",
    "print(\"=\" * 50)\n",
    "for method in methods:\n",
    "    print(f\"{method.upper():>4}: Optimal order = {results[method]:2d}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "### Visualize Selection Criteria\n",
    "\n",
    "Plot the criterion values for each method to understand how they select the optimal order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot selection criteria\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "orders = np.arange(1, max_order + 1)\n",
    "\n",
    "for i, method in enumerate(methods):\n",
    "    ax = axes[i]\n",
    "    values = criterion_values[method]\n",
    "    optimal_order = results[method]\n",
    "    \n",
    "    # Plot criterion values\n",
    "    ax.plot(orders, values, 'o-', linewidth=2, markersize=4, label=f'{method.upper()} values')\n",
    "    \n",
    "    # Mark optimal order\n",
    "    ax.axvline(x=optimal_order, color='r', linestyle='--', alpha=0.7, \n",
    "               label=f'Optimal order: {optimal_order}')\n",
    "    \n",
    "    # Special handling for different methods\n",
    "    if method == 'paf':\n",
    "        # Add confidence interval lines for PAF\n",
    "        k = 2.0 / np.sqrt(t)\n",
    "        ax.axhline(y=k, color='g', linestyle=':', alpha=0.7, label=f'Upper limit: +{k:.4f}')\n",
    "        ax.axhline(y=-k, color='g', linestyle=':', alpha=0.7, label=f'Lower limit: -{k:.4f}')\n",
    "        ax.set_ylabel('Last AR Parameter')\n",
    "        ax.set_title(f'{method.upper()} Method\\n(Partial Autocorrelation Function)')\n",
    "        \n",
    "    elif method == 'svd':\n",
    "        ax.set_ylabel('Singular Values')\n",
    "        ax.set_title(f'{method.upper()} Method\\n(Singular Value Decomposition)')\n",
    "        ax.set_yscale('log')  # Log scale for better visualization\n",
    "        \n",
    "    elif method in ['aic', 'bic']:\n",
    "        # Mark minimum for information criteria\n",
    "        min_idx = np.argmin(values)\n",
    "        ax.plot(orders[min_idx], values[min_idx], 'ro', markersize=8, \n",
    "                label=f'Minimum: {values[min_idx]:.2f}')\n",
    "        ax.set_ylabel(f'{method.upper()} Value')\n",
    "        ax.set_title(f'{method.upper()} Method\\n({\"Akaike\" if method == \"aic\" else \"Bayesian\"} Information Criterion)')\n",
    "        \n",
    "    else:  # rms\n",
    "        ax.set_ylabel('RMS Error')\n",
    "        ax.set_title(f'{method.upper()} Method\\n(Root Mean Square Error)')\n",
    "    \n",
    "    ax.set_xlabel('AR Model Order')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend()\n",
    "    ax.set_xlim([1, max_order])\n",
    "\n",
    "# Remove empty subplot\n",
    "axes[-1].remove()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "### Compare AR Models at Different Orders\n",
    "\n",
    "Fit AR models at the orders suggested by different methods and compare their prediction performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a few representative orders for comparison\n",
    "comparison_orders = [results['aic'], results['bic'], results['paf']]\n",
    "comparison_orders = sorted(list(set(comparison_orders)))  # Remove duplicates and sort\n",
    "\n",
    "print(f\"Comparing AR models at orders: {comparison_orders}\")\n",
    "\n",
    "# Prepare data for AR modeling (need 3D format)\n",
    "data_3d = channel_5_baseline.reshape(-1, 1, 1)  # (TIME, CHANNELS, INSTANCES)\n",
    "\n",
    "# Fit AR models and compute performance metrics\n",
    "model_performance = {}\n",
    "\n",
    "for order in comparison_orders:\n",
    "    print(f\"\\nFitting AR({order}) model...\")\n",
    "    \n",
    "    # Fit AR model\n",
    "    ar_params_fv, rms_fv, ar_params, ar_residuals, ar_prediction = ar_model(data_3d, order)\n",
    "    \n",
    "    # Compute performance metrics\n",
    "    prediction_error = np.mean(ar_residuals[:, 0, 0]**2)  # MSE\n",
    "    prediction_rmse = np.sqrt(prediction_error)\n",
    "    \n",
    "    # R-squared (coefficient of determination)\n",
    "    total_variance = np.var(channel_5_baseline)\n",
    "    residual_variance = np.var(ar_residuals[:, 0, 0])\n",
    "    r_squared = 1 - (residual_variance / total_variance)\n",
    "    \n",
    "    model_performance[order] = {\n",
    "        'mse': prediction_error,\n",
    "        'rmse': prediction_rmse,\n",
    "        'r_squared': r_squared,\n",
    "        'residuals': ar_residuals[:, 0, 0],\n",
    "        'prediction': ar_prediction[:, 0, 0]\n",
    "    }\n",
    "    \n",
    "    print(f\"  MSE: {prediction_error:.6f}\")\n",
    "    print(f\"  RMSE: {prediction_rmse:.6f}\")\n",
    "    print(f\"  R-squared: {r_squared:.6f}\")\n",
    "\n",
    "# Display comparison table\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"AR MODEL PERFORMANCE COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Order':<8} {'MSE':<12} {'RMSE':<12} {'R-squared':<12}\")\n",
    "print(\"-\" * 60)\n",
    "for order in comparison_orders:\n",
    "    perf = model_performance[order]\n",
    "    print(f\"{order:<8} {perf['mse']:<12.6f} {perf['rmse']:<12.6f} {perf['r_squared']:<12.6f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "### Visualize Model Predictions and Residuals\n",
    "\n",
    "Compare the prediction accuracy and residual patterns for different AR model orders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot model predictions (zoomed view)\n",
    "zoom_start = 1000\n",
    "zoom_end = 1500\n",
    "zoom_range = slice(zoom_start, zoom_end)\n",
    "time_zoom = np.arange(zoom_start + 1, zoom_end + 1)\n",
    "\n",
    "fig, axes = plt.subplots(len(comparison_orders), 1, figsize=(14, 4*len(comparison_orders)))\n",
    "if len(comparison_orders) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for i, order in enumerate(comparison_orders):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Plot original signal and prediction\n",
    "    ax.plot(time_zoom, channel_5_baseline[zoom_range], 'k-', linewidth=1.5, \n",
    "            label='Original Signal', alpha=0.8)\n",
    "    ax.plot(time_zoom, model_performance[order]['prediction'][zoom_range], 'r--', \n",
    "            linewidth=1.5, label=f'AR({order}) Prediction', alpha=0.8)\n",
    "    \n",
    "    ax.set_title(f'AR({order}) Model Prediction (Points {zoom_start+1}-{zoom_end})', \n",
    "                 fontweight='bold')\n",
    "    ax.set_xlabel('Time Points')\n",
    "    ax.set_ylabel('Acceleration (g)')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add performance metrics as text\n",
    "    perf = model_performance[order]\n",
    "    ax.text(0.02, 0.98, f\"R² = {perf['r_squared']:.4f}\\nRMSE = {perf['rmse']:.6f}\", \n",
    "            transform=ax.transAxes, verticalalignment='top',\n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot residuals analysis\n",
    "fig, axes = plt.subplots(len(comparison_orders), 2, figsize=(16, 4*len(comparison_orders)))\n",
    "if len(comparison_orders) == 1:\n",
    "    axes = axes.reshape(1, -1)\n",
    "\n",
    "for i, order in enumerate(comparison_orders):\n",
    "    residuals = model_performance[order]['residuals']\n",
    "    \n",
    "    # Time series plot of residuals\n",
    "    axes[i, 0].plot(time_zoom, residuals[zoom_range], 'b-', linewidth=1.0, alpha=0.7)\n",
    "    axes[i, 0].axhline(y=0, color='k', linestyle='--', alpha=0.5)\n",
    "    axes[i, 0].set_title(f'AR({order}) Residuals (Points {zoom_start+1}-{zoom_end})')\n",
    "    axes[i, 0].set_xlabel('Time Points')\n",
    "    axes[i, 0].set_ylabel('Residual')\n",
    "    axes[i, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Histogram of residuals\n",
    "    axes[i, 1].hist(residuals, bins=50, alpha=0.7, color='blue', density=True)\n",
    "    axes[i, 1].set_title(f'AR({order}) Residuals Distribution')\n",
    "    axes[i, 1].set_xlabel('Residual Value')\n",
    "    axes[i, 1].set_ylabel('Density')\n",
    "    axes[i, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add statistics\n",
    "    mean_res = np.mean(residuals)\n",
    "    std_res = np.std(residuals)\n",
    "    axes[i, 1].text(0.02, 0.98, f\"Mean = {mean_res:.6f}\\nStd = {std_res:.6f}\", \n",
    "                    transform=axes[i, 1].transAxes, verticalalignment='top',\n",
    "                    bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "### Method Comparison and Recommendations\n",
    "\n",
    "Analyze the results and provide guidance on method selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary comparison\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AR MODEL ORDER SELECTION METHOD COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nMethod Characteristics:\")\n",
    "print(\"-\" * 40)\n",
    "print(\"AIC (Akaike Information Criterion):\")\n",
    "print(f\"  • Suggested order: {results['aic']}\")\n",
    "print(\"  • Balances model fit vs. complexity\")\n",
    "print(\"  • Tends to select higher orders than BIC\")\n",
    "print(\"  • Good for prediction applications\\n\")\n",
    "\n",
    "print(\"BIC (Bayesian Information Criterion):\")\n",
    "print(f\"  • Suggested order: {results['bic']}\")\n",
    "print(\"  • More conservative than AIC\")\n",
    "print(\"  • Stronger penalty for model complexity\")\n",
    "print(\"  • Good for model selection and interpretation\\n\")\n",
    "\n",
    "print(\"PAF (Partial Autocorrelation Function):\")\n",
    "print(f\"  • Suggested order: {results['paf']}\")\n",
    "print(\"  • Based on statistical significance testing\")\n",
    "print(\"  • Uses confidence intervals for white noise\")\n",
    "print(\"  • Traditional time series approach\\n\")\n",
    "\n",
    "print(\"SVD (Singular Value Decomposition):\")\n",
    "print(f\"  • Suggested order: {results['svd']}\")\n",
    "print(\"  • Analyzes rank structure of data matrix\")\n",
    "print(\"  • Good for identifying dominant patterns\")\n",
    "print(\"  • Robust to noise\\n\")\n",
    "\n",
    "print(\"RMS (Root Mean Square Error):\")\n",
    "print(f\"  • Suggested order: {results['rms']}\")\n",
    "print(\"  • Based on prediction error improvement\")\n",
    "print(\"  • Simple and intuitive approach\")\n",
    "print(\"  • May overfit with high orders\\n\")\n",
    "\n",
    "# Consensus analysis\n",
    "orders_list = list(results.values())\n",
    "unique_orders = list(set(orders_list))\n",
    "order_counts = {order: orders_list.count(order) for order in unique_orders}\n",
    "\n",
    "print(\"Order Selection Consensus:\")\n",
    "print(\"-\" * 30)\n",
    "for order in sorted(unique_orders):\n",
    "    count = order_counts[order]\n",
    "    methods_for_order = [method for method, selected_order in results.items() if selected_order == order]\n",
    "    print(f\"Order {order:2d}: Selected by {count} method(s) - {', '.join(methods_for_order).upper()}\")\n",
    "\n",
    "print(\"\\nRecommendations:\")\n",
    "print(\"-\" * 20)\n",
    "most_common_order = max(order_counts, key=order_counts.get)\n",
    "if order_counts[most_common_order] > 1:\n",
    "    print(f\"• Consensus choice: AR({most_common_order}) - selected by multiple methods\")\n",
    "else:\n",
    "    print(\"• No clear consensus - consider application-specific requirements\")\n",
    "\n",
    "print(f\"• Conservative choice: AR({results['bic']}) (BIC method)\")\n",
    "print(f\"• Prediction-focused: AR({results['aic']}) (AIC method)\")\n",
    "print(f\"• Traditional approach: AR({results['paf']}) (PAF method)\")\n",
    "\n",
    "print(\"\\n• For SHM applications: Lower orders (5-15) often sufficient for damage detection\")\n",
    "print(\"• Consider computational cost vs. performance trade-offs\")\n",
    "print(\"• Validate with actual damage detection performance if possible\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This example demonstrated comprehensive AR model order selection using five different methods:\n",
    "\n",
    "1. **AIC and BIC**: Information criteria that balance model fit against complexity\n",
    "2. **PAF**: Statistical significance testing of AR parameters\n",
    "3. **SVD**: Matrix rank analysis approach\n",
    "4. **RMS**: Direct prediction error minimization\n",
    "\n",
    "**Key Insights:**\n",
    "\n",
    "- **No Universal \"Best\" Method**: Different methods can suggest different optimal orders\n",
    "- **Application-Dependent Choice**: The optimal method depends on your specific use case:\n",
    "  - **Damage Detection**: Lower orders often sufficient (5-15)\n",
    "  - **Prediction**: AIC often performs well\n",
    "  - **Model Interpretation**: BIC provides more conservative estimates\n",
    "  - **Noise Robustness**: SVD can be more robust to measurement noise\n",
    "\n",
    "- **Practical Considerations**:\n",
    "  - Higher orders increase computational cost\n",
    "  - Overfitting risk with very high orders\n",
    "  - Cross-validation can help validate order choice\n",
    "  - Consider multiple methods and look for consensus\n",
    "\n",
    "**For Structural Health Monitoring:**\n",
    "\n",
    "The choice of AR order affects the quality of damage-sensitive features. This example provides a systematic approach to select appropriate orders based on data characteristics and application requirements. The methods implemented here can be used as a preprocessing step before applying outlier detection algorithms like those demonstrated in the PCA, Mahalanobis, SVD, and Factor Analysis examples.\n",
    "\n",
    "**See also:**\n",
    "- [Outlier Detection based on Principal Component Analysis](pca_outlier_detection.ipynb)\n",
    "- [Outlier Detection based on Mahalanobis Distance](mahalanobis_outlier_detection.ipynb)\n",
    "- [Outlier Detection based on Singular Value Decomposition](svd_outlier_detection.ipynb)\n",
    "- [Outlier Detection based on Factor Analysis](../intermediate/factor_analysis_outlier_detection.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}