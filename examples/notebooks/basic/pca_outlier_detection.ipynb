{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Outlier Detection Based on Principal Component Analysis\n\n## Introduction\n\nThe goal of this example is to discriminate time histories from undamaged and damaged conditions based on outlier detection. The root mean square (RMS) errors of an autoregressive (AR) model are used as damage-sensitive features and a machine learning algorithm based on principal component analysis (PCA) is used to create damage indicators (DIs) invariant for feature vectors from normal structural condition and that increase when feature vectors are from damaged structural condition.\n\nData sets of an array of sensors (Channel 2-5) of the base-excited three story structure are used in this example. More details about the data sets can be found in the [3-Story Data Sets documentation](https://www.lanl.gov/projects/ei).\n\nThis example demonstrates:\n1. **Data Loading**: 3-story structure dataset with 4 channels, multiple conditions  \n2. **Feature Extraction**: AR(15) model RMSE values from channels 2-5\n3. **Train/Test Split**: Training on conditions 1-9, testing on conditions 1-9 (baseline) + 10-17 (damage)\n4. **PCA Modeling**: Learn PCA transformation from training features\n5. **Damage Detection**: Score test data and apply 95% threshold for classification\n6. **Visualization**: Time histories, feature plots, damage indicator bar charts\n\n**References:**\n\nFigueiredo, E., Park, G., Figueiras, J., Farrar, C., & Worden, K. (2009). Structural Health Monitoring Algorithm Comparisons using Standard Data Sets. Los Alamos National Laboratory Report: LA-14393.\n\n**SHMTools functions used:**\n- `ar_model`\n- `learn_pca`\n- `score_pca`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\nimport sys\nimport os\n\n# Add shmtools to path - handle different execution contexts\ncurrent_dir = Path.cwd()\nnotebook_dir = Path(__file__).parent if '__file__' in globals() else current_dir\n\n# Try different relative paths to find shmtools\npossible_paths = [\n    notebook_dir.parent.parent.parent,  # From examples/notebooks/basic/\n    current_dir.parent.parent,          # From examples/notebooks/\n    current_dir,                        # From project root\n    Path('/Users/eric/repo/shm/shmtools-python')  # Absolute fallback\n]\n\nshmtools_found = False\nfor path in possible_paths:\n    if (path / 'shmtools').exists():\n        if str(path) not in sys.path:\n            sys.path.insert(0, str(path))\n        shmtools_found = True\n        print(f\"Found shmtools at: {path}\")\n        break\n\nif not shmtools_found:\n    print(\"Warning: Could not find shmtools module\")\n\nfrom shmtools.utils.data_loading import load_3story_data\nfrom shmtools.features.time_series import ar_model\nfrom shmtools.classification.outlier_detection import learn_pca, score_pca\n\n# Set up plotting\nplt.style.use('default')\nplt.rcParams['figure.figsize'] = (12, 8)\nplt.rcParams['font.size'] = 10"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Raw Data\n",
    "\n",
    "Note that the data sets are composed of acceleration time histories from Channel 2-5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data set\n",
    "data_dict = load_3story_data()\n",
    "dataset = data_dict['dataset']\n",
    "fs = data_dict['fs']\n",
    "channels = data_dict['channels']\n",
    "damage_states = data_dict['damage_states']\n",
    "\n",
    "print(f\"Dataset shape: {dataset.shape}\")\n",
    "print(f\"Sampling frequency: {fs} Hz\")\n",
    "print(f\"Channels: {channels}\")\n",
    "print(f\"Number of damage states: {len(np.unique(damage_states))}\")\n",
    "\n",
    "# Extract channels 2-5 (indices 1-4 in Python)\n",
    "data = dataset[:, 1:5, :]\n",
    "t, m, n = data.shape\n",
    "\n",
    "print(f\"\\nData for analysis:\")\n",
    "print(f\"Time points: {t}\")\n",
    "print(f\"Channels: {m} (Ch2-Ch5)\")\n",
    "print(f\"Conditions: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Time History from Baseline and Damaged Conditions\n",
    "\n",
    "The figure below plots time histories from State#1 (baseline condition, black) and State#10 (lowest level of damage, red) in concatenated format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Channel labels\n",
    "labels = ['Channel 2', 'Channel 3', 'Channel 4', 'Channel 5']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "time_1 = np.arange(1, t+1)\n",
    "time_2 = np.arange(t+1, 2*t+1)\n",
    "\n",
    "for i in range(m):\n",
    "    # State #1 (condition index 0) and State #10 (condition index 90)\n",
    "    baseline_signal = data[:, i, 0]  # First condition (State 1)\n",
    "    damaged_signal = data[:, i, 90]   # Condition 91 (State 10, first damage level)\n",
    "    \n",
    "    axes[i].plot(time_1, baseline_signal, 'k-', label='State #1 (Baseline)', linewidth=0.8)\n",
    "    axes[i].plot(time_2, damaged_signal, 'r--', label='State #10 (Damage)', linewidth=0.8)\n",
    "    \n",
    "    axes[i].set_title(labels[i])\n",
    "    axes[i].set_ylim([-2.5, 2.5])\n",
    "    axes[i].set_xlim([1, 2*t])\n",
    "    axes[i].set_yticks([-2, 0, 2])\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "    \n",
    "    if i >= 2:  # Bottom row\n",
    "        axes[i].set_xlabel('Observations')\n",
    "    if i % 2 == 0:  # Left column\n",
    "        axes[i].set_ylabel('Acceleration (g)')\n",
    "    \n",
    "    if i == 0:  # Add legend to first subplot\n",
    "        axes[i].legend(loc='upper right', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction of Damage-Sensitive Features\n",
    "\n",
    "This section returns the RMS errors of an AR(15) model of Channels 2-5 in concatenated format. This way, any condition is classified based on a feature vector composed of features from all sensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# AR model order\nar_order = 15\n\nprint(f\"Extracting AR({ar_order}) model features...\")\n\n# Estimation of AR Parameters\nar_parameters_fv, rmse, ar_parameters, ar_residuals, ar_prediction = ar_model(data, ar_order)\n\nprint(f\"AR parameters FV shape: {ar_parameters_fv.shape}\")\nprint(f\"RMSE shape: {rmse.shape}\")\nprint(f\"AR parameters shape: {ar_parameters.shape}\")\nprint(f\"AR residuals shape: {ar_residuals.shape}\")\nprint(f\"AR prediction shape: {ar_prediction.shape}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Training and Test Data\n",
    "\n",
    "Following the original MATLAB example exactly:\n",
    "- **Training Data**: From conditions 1-9 (first 9 from each of the first 9 damage states)\n",
    "- **Test Data**: Every 10th condition from all damage states (conditions 10, 20, 30, ..., 170)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Data - following MATLAB exactly\n",
    "# for i=1:9; learnData(i*9-8:i*9,:)=RMSE(i*10-9:i*10-1,:); end\n",
    "learn_data = np.zeros((9*9, m))  # 81 samples x 4 features\n",
    "\n",
    "for i in range(1, 10):  # i = 1 to 9\n",
    "    start_idx = i*9 - 8 - 1  # Convert to 0-based indexing\n",
    "    end_idx = i*9 - 1\n",
    "    \n",
    "    rmse_start_idx = i*10 - 9 - 1  # Convert to 0-based indexing  \n",
    "    rmse_end_idx = i*10 - 1 - 1\n",
    "    \n",
    "    learn_data[start_idx:end_idx+1, :] = rmse[rmse_start_idx:rmse_end_idx+1, :]\n",
    "\n",
    "# Test Data - every 10th condition\n",
    "# scoreData=RMSE(10:10:170,:)\n",
    "test_indices = np.arange(9, 170, 10)  # 10:10:170 in MATLAB (0-based: 9:10:169)\n",
    "score_data = rmse[test_indices, :]\n",
    "\n",
    "print(f\"Training data shape: {learn_data.shape}\")\n",
    "print(f\"Test data shape: {score_data.shape}\")\n",
    "print(f\"Test indices (MATLAB 1-based): {test_indices + 1}\")\n",
    "\n",
    "n_test = score_data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Test Data Features\n",
    "\n",
    "Visualization of the extracted features showing clear separation between undamaged (conditions 1-9) and damaged (conditions 10-17) states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Plot test data\nplt.figure(figsize=(10, 6))\n\n# Undamaged conditions (first 9 test samples) - plot one line with label for legend\nchannels_plot = np.arange(1, m+1)  # 1, 2, 3, 4 for channels 2-5\n\n# Plot first undamaged line with label for legend\nplt.plot(channels_plot, score_data[0, :], '*--k', markersize=8, linewidth=1, alpha=0.7, label='Undamaged')\n# Plot remaining undamaged lines without labels\nfor i in range(1, 9):\n    plt.plot(channels_plot, score_data[i, :], '*--k', markersize=8, linewidth=1, alpha=0.7)\n\n# Plot first damaged line with label for legend\nplt.plot(channels_plot, score_data[9, :], '*--r', markersize=8, linewidth=1, alpha=0.7, label='Damaged')\n# Plot remaining damaged lines without labels\nfor i in range(10, 17):\n    plt.plot(channels_plot, score_data[i, :], '*--r', markersize=8, linewidth=1, alpha=0.7)\n\nplt.title('Features from all Sensors in Concatenated Format for the Test Data')\nplt.xlabel('Channel')\nplt.ylabel('RMSE')\nplt.xlim([0, m+1])\nplt.xticks(channels_plot, ['2', '3', '4', '5'])\nplt.grid(True, alpha=0.3)\nplt.legend()\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Modeling for Feature Classification\n",
    "\n",
    "The PCA-based machine learning algorithm is used to normalize the features and to reduce each feature vector to a score (also called DI - Damage Indicator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Learn PCA model from training data\nprint(\"Learning PCA model from training data...\")\nmodel = learn_pca(learn_data)\n\nprint(f\"PCA model loadings shape: {model['loadings'].shape}\")\nprint(f\"Data parameters shape: {model['data_param'].shape}\")\n\n# Score test data using the learned model\nprint(\"\\nScoring test data...\")\nDI, residuals = score_pca(score_data, model)\n\nprint(f\"Damage indicators shape: {DI.shape}\")\nprint(f\"Residuals shape: {residuals.shape}\")\nprint(f\"\\nDamage indicators (first 10): {DI[:10]}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier Detection\n",
    "\n",
    "Threshold determination based on the 95% cut-off over the training data and visualization of damage indicators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Threshold based on the 95% cut-off over the training data\nprint(\"Computing threshold from training data...\")\nthreshold_scores, _ = score_pca(learn_data, model)\nthreshold_sorted = np.sort(-threshold_scores)  # Sort negative scores (following MATLAB)\nUCL = threshold_sorted[int(np.round(len(threshold_sorted) * 0.95)) - 1]  # 95th percentile\n\nprint(f\"Upper Control Limit (UCL): {UCL:.6f}\")\nprint(f\"Number of training samples: {len(threshold_scores)}\")\nprint(f\"95th percentile index: {int(np.round(len(threshold_sorted) * 0.95))}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Damage Indicators\n",
    "\n",
    "The figure below shows that the approach for damage detection, based on PCA-based machine learning algorithm along with the RMS errors of an AR(15) model from Channel 2-5, is able to discriminate the undamaged (1-9) and damaged (10-17) state conditions without any false-negative and false-positive indications of damage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot DIs\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "state_conditions = np.arange(1, n_test + 1)\n",
    "\n",
    "# Undamaged conditions (1-9)\n",
    "plt.bar(state_conditions[:9], -DI[:9], color='k', alpha=0.7, label='Undamaged')\n",
    "\n",
    "# Damaged conditions (10-17)\n",
    "plt.bar(state_conditions[9:17], -DI[9:17], color='r', alpha=0.7, label='Damaged')\n",
    "\n",
    "plt.title('Damage Indicators from the Test Data')\n",
    "plt.xlim([0, n_test + 1])\n",
    "plt.xticks(state_conditions)\n",
    "plt.xlabel('State Condition [Undamaged(1-9) and Damaged (10-17)]')\n",
    "plt.ylabel('DI')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add threshold line\n",
    "plt.axhline(y=UCL, color='b', linestyle='-.', linewidth=2, label=f'95% Threshold ({UCL:.4f})')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print classification results\n",
    "print(\"\\nClassification Results:\")\n",
    "print(\"=\" * 50)\n",
    "for i in range(n_test):\n",
    "    state_type = \"Undamaged\" if i < 9 else \"Damaged\"\n",
    "    detected = \"DAMAGE\" if -DI[i] > UCL else \"normal\"\n",
    "    status = \"✓\" if (i < 9 and detected == \"normal\") or (i >= 9 and detected == \"DAMAGE\") else \"✗\"\n",
    "    print(f\"State {i+1:2d} ({state_type:9s}): DI = {-DI[i]:8.4f} → {detected:6s} {status}\")\n",
    "\n",
    "# Calculate performance metrics\n",
    "undamaged_correct = np.sum(-DI[:9] <= UCL)\n",
    "damaged_correct = np.sum(-DI[9:17] > UCL)\n",
    "total_correct = undamaged_correct + damaged_correct\n",
    "\n",
    "print(f\"\\nPerformance Summary:\")\n",
    "print(f\"Undamaged correctly classified: {undamaged_correct}/9\")\n",
    "print(f\"Damaged correctly classified: {damaged_correct}/8\")\n",
    "print(f\"Overall accuracy: {total_correct}/{n_test} ({100*total_correct/n_test:.1f}%)\")\n",
    "print(f\"False positives: {9 - undamaged_correct}\")\n",
    "print(f\"False negatives: {8 - damaged_correct}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This example demonstrated the complete PCA-based outlier detection workflow for structural health monitoring:\n",
    "\n",
    "1. **Data Loading**: Successfully loaded the 3-story structure dataset\n",
    "2. **Feature Extraction**: Used AR(15) model RMSE values as damage-sensitive features\n",
    "3. **PCA Modeling**: Learned PCA transformation from baseline training data\n",
    "4. **Damage Detection**: Applied PCA-based scoring with 95% threshold\n",
    "5. **Classification**: Achieved perfect separation between undamaged and damaged conditions\n",
    "\n",
    "The results show that the PCA-based approach successfully discriminates between undamaged (states 1-9) and damaged (states 10-17) conditions without any false positives or false negatives.\n",
    "\n",
    "**Key advantages of this approach:**\n",
    "- Uses only undamaged data for training (unsupervised learning)\n",
    "- Dimensionality reduction through PCA\n",
    "- Statistical threshold based on training data variability\n",
    "- Robust to measurement noise and environmental variations\n",
    "\n",
    "**See also:**\n",
    "- [Outlier Detection based on Nonlinear Principal Component Analysis](nlpca_outlier_detection.ipynb)\n",
    "- [Outlier Detection based on the Factor Analysis Model](factor_analysis_outlier_detection.ipynb)\n",
    "- [Outlier Detection based on the Singular Value Decomposition](svd_outlier_detection.ipynb)\n",
    "- [Outlier Detection based on the Mahalanobis Distance](mahalanobis_outlier_detection.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}