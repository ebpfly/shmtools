{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# SHMTools Data Import Demo\n\nThis notebook demonstrates how to properly import and use the 3-story structure dataset with the corrected `import_3story_structure_shm()` function.\n\n## Key Changes:\n- Use `import_3story_structure_shm()` instead of the old `load_3story_data()`\n- The new function returns a tuple: `(dataset, damage_states, state_list)`\n- No more dictionary access - direct variable assignment"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Correct Data Loading"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom examples.data import import_3story_structure_shm\n\n# Load the 3-story structure dataset correctly\ndataset, damage_states, state_list = import_3story_structure_shm()\n\n# Convert state_list to expected format\nstates = state_list.flatten().astype(int)\n\nprint(f\"Dataset shape: {dataset.shape}\")\nprint(f\"Damage states shape: {damage_states.shape}\")  \nprint(f\"State list shape: {state_list.shape}\")\nprint(f\"States (first 10): {states[:10]}\")\n\n# Set up default metadata (since old convenience functions are gone)\nfs = 100  # Default sampling frequency\nchannels = ['Force', 'Channel 2', 'Channel 3', 'Channel 4', 'Channel 5']\n\nprint(f\"Sampling frequency: {fs} Hz\")\nprint(f\"Channels: {channels}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Check data availability - basic validation\nprint(\"Data validation:\")\nprint(f\"Dataset dimensions: {dataset.shape} (should be 8192, 5, 170)\")\nprint(f\"All finite values: {np.isfinite(dataset).all()}\")\nprint(f\"States range: {states.min()} to {states.max()}\")\nprint(f\"Unique states: {len(np.unique(states))}\")\n\n# Basic dataset statistics\nprint(f\"\\nDataset statistics:\")\nprint(f\"Mean: {np.mean(dataset):.6f}\")\nprint(f\"Std: {np.std(dataset):.6f}\")\nprint(f\"Min: {np.min(dataset):.6f}\")\nprint(f\"Max: {np.max(dataset):.6f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Extract Channels for Analysis (Common Pattern)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Extract channels 2-5 (acceleration channels) as commonly done in examples\nsignals = dataset[:, 1:5, :]  # Skip channel 0 (force)\nt, m, n = signals.shape\n\nprint(f\"Extracted signals shape: {signals.shape}\")\nprint(f\"Time points (t): {t}\")\nprint(f\"Channels (m): {m} (channels 2-5)\")  \nprint(f\"Conditions (n): {n}\")\n\n# Create damage state labels (0=undamaged, 1=damaged)\n# States 1-9 are undamaged, states 10-17 are damaged\nbinary_damage_states = (states >= 10).astype(int)\n\nprint(f\"Undamaged instances: {np.sum(binary_damage_states == 0)}\")\nprint(f\"Damaged instances: {np.sum(binary_damage_states == 1)}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Visualization of loaded data\nplt.figure(figsize=(12, 8))\n\n# Plot sample time histories\nplt.subplot(2, 1, 1)\nplt.plot(signals[:1000, 0, 0], 'k-', label='Channel 2, State 1 (Undamaged)', linewidth=0.8)\nplt.plot(signals[:1000, 0, 90], 'r--', label='Channel 2, State 10 (Damaged)', linewidth=0.8)\nplt.title('Sample Time Histories from Loaded Data')\nplt.xlabel('Time points')\nplt.ylabel('Acceleration')\nplt.legend()\nplt.grid(True, alpha=0.3)\n\n# Plot damage state distribution\nplt.subplot(2, 1, 2)\nunique_states, counts = np.unique(states, return_counts=True)\ncolors = ['blue' if s <= 9 else 'red' for s in unique_states]\nplt.bar(unique_states, counts, color=colors, alpha=0.7)\nplt.xlabel('Damage State')\nplt.ylabel('Number of Tests')\nplt.title('Distribution of Test Conditions by Damage State')\nplt.xticks(unique_states)\nplt.grid(True, alpha=0.3)\n\n# Add legend\nimport matplotlib.patches as mpatches\nundamaged_patch = mpatches.Patch(color='blue', alpha=0.7, label='Undamaged (1-9)')\ndamaged_patch = mpatches.Patch(color='red', alpha=0.7, label='Damaged (10-17)')\nplt.legend(handles=[undamaged_patch, damaged_patch])\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Other Available Import Functions"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Import other available datasets\nfrom examples.data import (\n    import_cbm_data_shm,\n    import_active_sense1_shm, \n    import_sensor_diagnostic_shm,\n    import_modal_osp_shm\n)\n\n# Test what datasets are available\ndatasets_info = {}\n\ntry:\n    cbm_dataset, cbm_damage_states, cbm_state_list, cbm_fs = import_cbm_data_shm()\n    datasets_info['CBM'] = f\"Shape: {cbm_dataset.shape}, Fs: {cbm_fs} Hz\"\nexcept FileNotFoundError:\n    datasets_info['CBM'] = \"Not available (missing data_CBM.mat)\"\n\ntry:\n    sensor_healthy, sensor_example = import_sensor_diagnostic_shm()\n    datasets_info['Sensor Diagnostic'] = f\"Healthy: {sensor_healthy.shape}, Example: {sensor_example.shape}\"\nexcept FileNotFoundError:\n    datasets_info['Sensor Diagnostic'] = \"Not available (missing dataSensorDiagnostic.mat)\"\n\ntry:\n    nodes, elements, modes, resp_dof = import_modal_osp_shm()\n    datasets_info['Modal OSP'] = f\"Nodes: {nodes.shape}, Modes: {modes.shape}\"\nexcept FileNotFoundError:\n    datasets_info['Modal OSP'] = \"Not available (missing data_OSPExampleModal.mat)\"\n\ntry:\n    (waveform_base, waveform_test, sensor_layout, pair_list,\n     border_struct, sample_rate, actuation_waveform, damage_location) = import_active_sense1_shm()\n    datasets_info['Active Sensing'] = f\"Base: {waveform_base.shape}, Test: {waveform_test.shape}\"\nexcept FileNotFoundError:\n    datasets_info['Active Sensing'] = \"Not available (missing data_example_ActiveSense.mat)\"\n\nprint(\"Available datasets:\")\nfor name, info in datasets_info.items():\n    print(f\"  {name}: {info}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Usage Pattern for Notebook Examples"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Typical usage pattern for SHM analysis notebooks\nprint(\"Typical notebook setup pattern:\")\nprint()\n\nsetup_code = '''\n# Standard imports\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom examples.data import import_3story_structure_shm\n\n# Load data\ndataset, damage_states, state_list = import_3story_structure_shm()\nstates = state_list.flatten().astype(int)\n\n# Extract channels 2-5 for analysis  \ndata = dataset[:, 1:5, :]\nt, m, n = data.shape\n\n# Create binary damage labels\nbinary_labels = (states >= 10).astype(int)\n'''\n\nprint(setup_code)\n\nprint(\"This pattern works for:\")\nprint(\"- PCA outlier detection\")\nprint(\"- SVD outlier detection\") \nprint(\"- Mahalanobis distance\")\nprint(\"- Factor analysis\")\nprint(\"- AR model analysis\")\nprint(\"- And most other SHM examples\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Summary\n\n**Key changes from old system:**\n1. Use `import_3story_structure_shm()` instead of `load_3story_data()`\n2. Function returns tuple: `(dataset, damage_states, state_list)`\n3. No more dictionary access - direct variable assignment\n4. Convert `state_list` to flat array: `states = state_list.flatten().astype(int)`\n5. Use default values for metadata (fs=100, channel names)\n\n**This corrected pattern is now used in all fixed notebooks.**"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}